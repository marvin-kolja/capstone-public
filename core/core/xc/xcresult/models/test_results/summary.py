# generated by datamodel-codegen:
#   filename:  core/scripts/xcresult_model_generator/schemas/test_results/summary.json
#   timestamp: 2025-01-10T14:31:12+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Field


class InsightSummary(BaseModel):
    impact: str
    category: str
    text: str


class TestResult(Enum):
    Passed = 'Passed'
    Failed = 'Failed'
    Skipped = 'Skipped'
    Expected_Failure = 'Expected Failure'
    unknown = 'unknown'


class Statistic(BaseModel):
    title: str
    subtitle: str


class Device(BaseModel):
    deviceId: Optional[str] = None
    deviceName: str
    architecture: str
    modelName: str
    platform: Optional[str] = None
    osVersion: str


class Configuration(BaseModel):
    configurationId: str
    configurationName: str


class TestFailure(BaseModel):
    testName: str
    targetName: str
    failureText: str
    testIdentifier: int


class DeviceAndConfigurationSummary(BaseModel):
    device: Device
    testPlanConfiguration: Configuration
    passedTests: int
    failedTests: int
    skippedTests: int
    expectedFailures: int


class Summary(BaseModel):
    title: str
    startTime: Optional[float] = Field(
        None,
        description='Date as a UNIX timestamp (seconds since midnight UTC on January 1, 1970)',
    )
    finishTime: Optional[float] = Field(
        None,
        description='Date as a UNIX timestamp (seconds since midnight UTC on January 1, 1970)',
    )
    environmentDescription: str = Field(
        ...,
        description='Description of the Test Plan, OS, and environment that was used during testing',
    )
    topInsights: List[InsightSummary]
    result: TestResult
    totalTestCount: int
    passedTests: int
    failedTests: int
    skippedTests: int
    expectedFailures: int
    statistics: List[Statistic]
    devicesAndConfigurations: List[DeviceAndConfigurationSummary]
    testFailures: List[TestFailure]
